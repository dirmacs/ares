[package]
name = "ares"
version = "0.1.1"
edition = "2021"
description = "A.R.E.S - Agentic Retrieval Enhanced Server: A production-grade agentic chatbot server with multi-provider LLM support"
license = "MIT"
repository = "https://github.com/your-org/ares"
readme = "README.md"
keywords = ["llm", "chatbot", "agent", "rag", "ai"]
categories = ["web-programming", "asynchronous"]

[features]
# Default features for local-first development
default = ["local-db", "ollama"]

# ============= LLM Providers =============
# Ollama - Local LLM inference via Ollama server
ollama = ["dep:ollama-rs"]

# OpenAI - OpenAI API and compatible endpoints
openai = ["dep:async-openai"]

# LlamaCpp - Direct GGUF model loading via llama.cpp
llamacpp = ["dep:llama-cpp-2"]



# LlamaCpp GPU backends (mutually exclusive - pick one)
llamacpp-cuda = ["llamacpp", "llama-cpp-2/cuda"]
llamacpp-metal = ["llamacpp", "llama-cpp-2/metal"]
llamacpp-vulkan = ["llamacpp", "llama-cpp-2/vulkan"]

# ============= Database Backends =============
# Local SQLite database via libsql (default for local development)
local-db = []

# Remote Turso database support
turso = []

# Qdrant vector database for semantic search
qdrant = ["dep:qdrant-client"]

# ============= Additional Features =============
# MCP (Model Context Protocol) server support
mcp = ["dep:rmcp"]

# ============= Feature Bundles =============
# All LLM providers
all-llm = ["ollama", "openai", "llamacpp"]

# All database backends
all-db = ["local-db", "turso", "qdrant"]

# Full feature set for development/testing
full = ["ollama", "openai", "llamacpp", "turso", "qdrant", "mcp"]

# Minimal build - no optional features
minimal = []

[dependencies]
# Core dependencies
anyhow = "1.0.100"
async-stream = "0.3.6"
async-trait = "0.1.89"
chrono = { version = "0.4.42", features = ["serde"] }
futures = "0.3.29"
serde = { version = "1.0.228", features = ["derive"] }
serde_json = "1.0.145"
thiserror = "2.0.17"
tokio = { version = "1.48.0", features = ["full"] }
tracing = "0.1.43"
tracing-subscriber = { version = "0.3.22", features = ["env-filter", "json"] }
uuid = { version = "1.19.0", features = ["v4", "serde"] }

# Web framework
axum = { version = "0.8.7", features = ["macros", "multipart"] }
tower = { version = "0.5.2", features = ["full"] }
tower-http = { version = "0.6.7", features = ["trace", "cors", "compression-gzip"] }
tower-sessions = "0.14.0"

# HTTP client
reqwest = { version = "0.12.24", features = ["json"] }

# Authentication
argon2 = "0.5.3"
jsonwebtoken = { version = "10.2.0", features = ["rust_crypto"] }
sha2 = "0.11.0-rc.3"
rand = "0.9.2"

# Configuration
config = "0.15.19"
dotenv = "0.15.0"

# Database - libsql (always included for local-db)
libsql = { version = "0.9.29", features = ["core", "replication"] }

# Vector database (optional)
qdrant-client = { version = "1.16.0", optional = true }

# LLM Providers (optional)
ollama-rs = { version = "0.3.3", features = ["stream"], optional = true }
async-openai = { version = "0.31.1", features = ["chat-completion"], optional = true }
llama-cpp-2 = { version = "0.1.129", optional = true }



# Embeddings and RAG
fastembed = "5.3.1"
rig-core = "0.25.0"

# Web scraping and search
daedra = "0.1.2"
scraper = "0.24.0"

# Schema and documentation
schemars = { version = "1.1.0", features = ["derive"] }
utoipa = { version = "5.4.0", features = ["axum_extras", "chrono", "uuid"] }
utoipa-swagger-ui = { version = "9.0.2", features = ["axum"] }

# MCP support (optional)
rmcp = { version = "0.10.0", features = ["server", "client", "transport-io", "macros"], optional = true }

[dev-dependencies]
# Testing utilities
axum-test = "18.4.1"
mockall = "0.14.0"
rstest = "0.26.1"
tempfile = "3.23.0"
wiremock = "0.6.5"

# Note: cargo-llvm-cov is a CLI tool, not a library dependency
# Install with: cargo install cargo-llvm-cov

[profile.dev]
# Faster compile times for development
opt-level = 0
debug = true

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
strip = true

[profile.test]
opt-level = 0
debug = true

# Documentation settings
[package.metadata.docs.rs]
all-features = true
rustdoc-args = ["--cfg", "docsrs"]
